{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a03fbfde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cd02341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ba60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0220f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = config[\"API\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d80d8c45",
   "metadata": {},
   "source": [
    "## How to design good prompt - completion request\n",
    "- instruction (precise, direct)\n",
    "\n",
    "###INSTRUCTION###\n",
    "- data\n",
    "\n",
    "Data:\n",
    "- context\n",
    "\n",
    "Text: \n",
    "- output instruction (what type of output do you want? what type?)\n",
    "\n",
    "Output:\n",
    "\n",
    "### tips and tricks\n",
    "- you can add \"step by step\" when you want more 'mathematic' approach\n",
    "- you can add examples how you think and later on ask to do the same with the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f58f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request \n",
    "completion = openai.Completion.create(\n",
    "    model = 'text-davinci-003' #model type we use to generate response\n",
    "    , prompt = 'Who let the dogs out?' #prompt\n",
    "    , max_tokens = 200 #max number of tokens we want to use for response (we pay for them)\n",
    "    , stop = '11.' #when we want to stop - it stops before '11.'\n",
    "    , n = 1 #how many times we want to regenerate response\n",
    "    , echo = True #if question should be in the response\n",
    "    ,  temperature = 1 #value determines \"creativity\" of an answer - it changes probabilites of the next token\n",
    "    , top_p = 1 #value determines \"creativity\" of an answer - it cuts of or broaden the group of tokens the model can choose from\n",
    "    , stream = False #give the response imedately as it is, or wait for all the tokens\n",
    "    , frequency_penalty = 0 #punishes tokens which were used in a response earlier. Proportional to number of uses before in request\n",
    "    , presence_penalty = 0 #punishes tokens which were used in a response earlier. Not proportional to number of uses before in request\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5db29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b22843c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 1\n",
    "#the easiest response \n",
    "#you can choose from various models on openai websites, (may 2023) the best for api is text-davinci-003\n",
    "response = openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = 'Give me a list of 3 biggest countries'\n",
    "    , max_tokens = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e45c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"choices\"][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9519f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 2\n",
    "#when you want to stop before particular word\n",
    "response = openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = 'Give me a list of the biggest countries'\n",
    "    , max_tokens = 200\n",
    "    , stop = '11.'\n",
    "    , echo = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f3109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf7d7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a chatbot that is a rapper. \n",
    "User: HI, how are you\n",
    "Chatbot: I'm good\n",
    "User: Tell me about your family\n",
    "Chatbot: I have a mommy and a daddy\n",
    "User: Can you tell me about your day?\n",
    "Chatbot:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56dd1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 3\n",
    "response = openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = prompt\n",
    "    , max_tokens = 200\n",
    "    , stop = ['Chatbot', 'User'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "293f2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 4\n",
    "#you can regenerate response many times in one response\n",
    "joke = openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = 'tell me a joke about cows'\n",
    "    , max_tokens = 200\n",
    "    , n = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18352566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joke[\"choices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee43b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 5\n",
    "#echo \n",
    "#makes model re-say what you gave to him\n",
    "pet = openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = 'What is better: cats or dogs in one word'\n",
    "    , max_tokens = 100\n",
    "    , echo = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7629c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e358c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 6\n",
    "#temperature \n",
    "#makes model 0 - more deterministic to 2 - more creative/random\n",
    "#temperature make probabilities of next token less diffrent to each other when we raise temperature\n",
    "#usually between 0 and 1. deafult 1\n",
    "friend = {f\"temperature {temperature}\": openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = 'Who is the best friend of human kind?'\n",
    "    , max_tokens = 100\n",
    "    , temperature = temperature\n",
    ")[\"choices\"][0][\"text\"] for temperature in (0, 0.5, 1, 1.5, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3f4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0db970a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 7\n",
    "#Top P \n",
    "#deafult 1, between 0 to 1\n",
    "#it controls the set of possible tokens the model can choose from\n",
    "#0 is more restrictive, 1 is the most creative\n",
    "#openai recomends using temperature xor top p\n",
    "mathematician = {f\"Top P {top_p}\": openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = 'Give me the name of the most famous mathematitian in the world'\n",
    "    , max_tokens = 100\n",
    "    , top_p = top_p\n",
    ")[\"choices\"][0][\"text\"] for top_p in (0, 0.25, 0.5, 0.75, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44fc000",
   "metadata": {},
   "outputs": [],
   "source": [
    "mathematician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3909581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 8\n",
    "#frequancy penalty\n",
    "#default 0,from -2 to 2\n",
    "#positive value penalize the tokens which appeared in answer\n",
    "#positive value decrease likelihood to repeat\n",
    "pet_suburbs = {f\"frequency penalty {freq}\": openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = 'The best pet animal to small house on suburbs is: '\n",
    "    , max_tokens = 100\n",
    "    , frequency_penalty = freq\n",
    ")[\"choices\"][0][\"text\"] for freq in (-2, -1, 0, 1, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c663faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_suburbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1d129b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 9\n",
    "#frequancy penalty\n",
    "#second ex\n",
    "countries = {f\"frequency penalty {freq}\": openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = 'List countries in western Europe: '\n",
    "    , max_tokens = 100\n",
    "    , frequency_penalty = freq\n",
    ")[\"choices\"][0][\"text\"] for freq in (-2, -1, 0, 1, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bef04b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 10\n",
    "#presence penalty\n",
    "#it works similar to frequency penalty\n",
    "#the difference it that frequency penalty is proportional to how often token has already been used\n",
    "#the presence penalty applies to all tokens that has been used at least once, so there is\n",
    "#no difference how often tokens have appeared in the result\n",
    "countries = {f\"presence penalty {freq}\": openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = 'List countries in western Europe: germany, netherlands, '\n",
    "    , max_tokens = 100\n",
    "    , presence_penalty = freq\n",
    ")[\"choices\"][0][\"text\"] for freq in (-2, -1, 0, 1, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b75f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db774ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion request example 11\n",
    "#stream\n",
    "#defaults to false\n",
    "#bolean value\n",
    "#if true - responce is send back in partial \n",
    "for parts in openai.Completion.create(\n",
    "    model = 'text-davinci-003'\n",
    "    , prompt = 'Tell me a short limeric'\n",
    "    , max_tokens = 300\n",
    "    , stream = True\n",
    "):\n",
    "    print(parts[\"choices\"][0][\"text\"], end = \"\", flush = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
