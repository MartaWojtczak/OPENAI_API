{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import pickle\n",
    "from nomic import atlas\n",
    "from openai.embeddings_utils import distances_from_embeddings, indices_of_nearest_neighbors_from_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "openai.api_key = config[\"API\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data set from https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots\n",
    "dataset_path = \"./wiki_movie_plots.csv\"\n",
    "source_df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = source_df[source_df[\"Origin/Ethnicity\"]==\"American\"].sort_values(\"Release Year\", ascending=False).head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embedding function\n",
    "@retry(wait=wait_random_exponential(min=1, max=10), stop=stop_after_attempt(6))\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text=text.replace(\"\\n\", \" \")\n",
    "    return openai.Embedding.create(input=text, model=model)[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establishing cache of embeddings to reduce cost and time\n",
    "embedding_cache_path = \"movie_embeddings_cache.pkl\"\n",
    "try:\n",
    "    embedding_cache = pd.read_pickle(embedding_cache_path)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "    pickle.dump(embedding_cache, embedding_cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to retrieve embeddings from the cache if present, \n",
    "#otherwise request via API\n",
    "\n",
    "def embedding_from_cache_or_API(\n",
    "    string, \n",
    "    model=\"text-embedding-ada-002\",\n",
    "    embedding_cache=embedding_cache\n",
    "):\n",
    "    if (string, model) not in embedding_cache.keys():\n",
    "        embedding_cache[(string, model)]=get_embedding(string, model)\n",
    "        print(\"I have just got embeddings from openai for you!\")\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "    return embedding_cache[(string, model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embeddings for movie plots\n",
    "plot_embeddings = [embedding_from_cache_or_API(plot) for plot in movies[\"Plot\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-28 13:29:04.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m91\u001b[0m - \u001b[33m\u001b[1mAn ID field was not specified in your data so one was generated for you in insertion order.\u001b[0m\n",
      "\u001b[32m2023-08-28 13:29:10.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m779\u001b[0m - \u001b[1mCreating project `harsh-being` in organization `wojtczakmart`\u001b[0m\n",
      "\u001b[32m2023-08-28 13:29:11.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mUploading embeddings to Atlas.\u001b[0m\n",
      "4it [00:04,  1.03s/it]                       \n",
      "\u001b[32m2023-08-28 13:29:16.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1411\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n",
      "\u001b[32m2023-08-28 13:29:16.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mEmbedding upload succeeded.\u001b[0m\n",
      "\u001b[32m2023-08-28 13:29:17.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.project\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1121\u001b[0m - \u001b[1mCreated map `harsh-being` in project `harsh-being`: https://atlas.nomic.ai/map/69b3aa10-a6bf-4814-9452-09c306fc9fde/2bb1c4e0-3c29-4a3b-906f-fa44d0c782d9\u001b[0m\n",
      "\u001b[32m2023-08-28 13:29:17.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_embeddings\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mharsh-being: https://atlas.nomic.ai/map/69b3aa10-a6bf-4814-9452-09c306fc9fde/2bb1c4e0-3c29-4a3b-906f-fa44d0c782d9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#atlas part with visualising results\n",
    "\n",
    "atlas_map = atlas.map_embeddings(\n",
    "    embeddings=np.array(plot_embeddings),\n",
    "    data=movies[[\"Title\", \"Genre\"]].to_dict(orient=\"records\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic movie recommendations\n",
    "\n",
    "def recommendations(\n",
    "    movie_title, \n",
    "    k_nearest_neighbours=3\n",
    "):\n",
    "    if  movie_title in movies[\"Title\"].values:\n",
    "        movie_plot = movies[movies[\"Title\"]==movie_title][\"Plot\"].values[0]\n",
    "    else:\n",
    "        return \"no movie in database\"\n",
    "    movie_embedding = embedding_cache[(movie_plot, \"text-embedding-ada-002\")]\n",
    "    movie_index = plot_embeddings.index(movie_embedding)\n",
    "    distances = distances_from_embeddings(movie_embedding, plot_embeddings)\n",
    "    indices = indices_of_nearest_neighbors_from_distances(distances)\n",
    "\n",
    "    match_counter = 0\n",
    "    matching_movies = []\n",
    "    for i in indices:\n",
    "        if i == movie_index:\n",
    "            continue\n",
    "        if match_counter >= k_nearest_neighbours:\n",
    "            break\n",
    "        match_counter += 1\n",
    "        matching_movies += [movies[movies[\"Plot\"]==list(embedding_cache.keys())[list(embedding_cache.values()).index(plot_embeddings[i])][0]][\"Title\"].values[0]]\n",
    "    return matching_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batman v Superman: Dawn of Justice',\n",
       " 'Hercules',\n",
       " 'Professor Marston and the Wonder Women']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations('Wonder Woman')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
